{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6799637",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aad319",
   "metadata": {},
   "source": [
    "In this lab we will make use of pretrained models in order to boost performance on smaller datasets. For this experiment, we will be working with an AlexNet model pretrained on the Imagenet dataset in order to get a good accuracy score on the Caltech 101 dataset.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. In order to perform the experiments, please download in advance the Caltech 101 dataset from https://drive.google.com/file/d/137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp/view\n",
    "2. In the working directory please create a folder named 'dataset' and a subfolder named 'caltech101' within it. Extract the dataset in the subfolder. The overall folder structure should look as follows: dataset/caltech101/101_ObjectCategories.\n",
    "3. Install the torchvision module using 'conda install torchvision' if you have not done so already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30288798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "# from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "NW = 4\n",
    "BS = 128\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19253b29",
   "metadata": {},
   "source": [
    "Firstly, we will load the AlexNet model architecture using torchvision. All available models with their respective parameters can be found at: https://pytorch.org/vision/stable/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f9c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81867c00",
   "metadata": {},
   "source": [
    "In the first run we will just load the model architecture, without the pretrained weights. We can visualize the model architecture as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40ab79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21109fdf",
   "metadata": {},
   "source": [
    "Next, we will load the Caltech 101 dataset and apply the neccesary transformations on it. Afterwards, we will split the dataset into train, validation and test.\n",
    "\n",
    "In this block of code, define the dataloaders for train, validation and test and try to iterate through the data. What happens? Try to fix the problem using a lambda transform: https://pytorch.org/vision/stable/transforms.html#generic-transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3027bcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.Caltech101(\n",
    "    './dataset',\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.PILToTensor(),\n",
    "        torchvision.transforms.ConvertImageDtype(torch.float),\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        # add a lambda transform in order to fix the problem\n",
    "        torchvision.transforms.Lambda(\n",
    "#             lambda img: img if img.shape[0] == 3 else torch.cat((img,img,img), 0)\n",
    "            lambda img: img if img.shape[0] == 3 else img.repeat(3, 1, 1)\n",
    "        )\n",
    "    ])\n",
    ")\n",
    "n_samples = len(dataset)\n",
    "n_train_samples = int(.8 * n_samples)\n",
    "n_val_samples = int(.1 * n_samples)\n",
    "n_test_samples = n_samples - n_train_samples - n_val_samples\n",
    "\n",
    "train_ds, val_ds, test_ds = torch.utils.data.random_split(dataset, [\n",
    "    n_train_samples, n_val_samples, n_test_samples\n",
    "])\n",
    "\n",
    "# define dataloaders for train, validation and test\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=BS, num_workers=NW)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, shuffle=True, batch_size=BS, num_workers=NW)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, shuffle=True, batch_size=BS, num_workers=NW)\n",
    "# iterate through the dataloaders\n",
    "item = iter(train_dl).next()\n",
    "print(item[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d6ec1",
   "metadata": {},
   "source": [
    "With the dataset ready, it is now time to adapt the model architecture in order to fit our needs. Define a new classifier for the AlexNet model having the same structure, changing only the number of output neurons to 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9baa894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6].out_features=101\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier[6].parameters():\n",
    "    param.requires_grad = True\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3abefe",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Define an Adam optimizer with a learining rate of 1e-4 and a cross entropy loss. Afterwards, train the model for 2 epochs. Note the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1210561",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "# define a Cross Entropy loss function\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb65ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_func, train_dl, val_dl, epochs):\n",
    "  \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for img, label in tqdm(train_dl):\n",
    "            \n",
    "            optimizer.zero_grad()     \n",
    "            \n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            output = model(img)\n",
    "            \n",
    "            loss = loss_func(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        accs = []\n",
    "        # return\n",
    "        for batch in val_dl:\n",
    "\n",
    "            img, label = batch\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(img)\n",
    "\n",
    "            predict = output.argmax(1)\n",
    "            acc = (predict == label).float().mean().detach().cpu().numpy()\n",
    "            accs.append(acc)\n",
    "    print(f\"{np.mean(accs)* 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f78fe60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346eaffc0bcc4fdc9d32a05530a40429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb66015bf354cf5b3897676d969eb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd306cb755db444a9c8deb3a81f96d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74%\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, loss_func, train_dl, val_dl, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d9a1e",
   "metadata": {},
   "source": [
    "## Experiments:\n",
    "\n",
    "1. Rerun training (restart kernel and run all cells) but this time, when loading the model in the first block of code, specify 'pretrained = True' in order to make use of the weights pretrained on Imagenet.\n",
    "2. Rerun the code using the pretrained model but this time use a learning rate of 1e-3. What happens?\n",
    "3. Rerun using the pretrained model and a lr of 1e-4 but this time only change the last layer in the model instead of the entire classifier.\n",
    "3. Rerun the code using the pretrained model and a lr of 1e-4. This time, freeze the pretrained layers and only update the new layers for the first epochs. Afterwards, proceed to update the entire model. You can freeze parameters by specifying 'requires_grad = False'.\n",
    "4. Rerun experiment 3 but gradually unfreeze layers instead of unfreezeing the entire model at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25412ec",
   "metadata": {},
   "source": [
    "1. acc = 79%\n",
    "2. acc = 10%\n",
    "3. acc  = 74%\n",
    "4. acc\n",
    "5. acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc522a7b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
